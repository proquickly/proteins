{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "          1. Load raw files\n",
      "          2. Match protein data\n",
      "          3. List match data\n",
      "          4. Save match data\n",
      "          5. Load match data\n",
      "          9. Quit\n",
      "          option = input()\n",
      "          \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import pprint\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "DATA = \"/Users/andy/data/proteins\"\n",
    "LIMIT = 5000\n",
    "intact_f = f\"{DATA}/intact.txt\"\n",
    "biogrid_f = f\"{DATA}/BIOGRID-ALL-4.4.222.tab3.txt\"\n",
    "db = sqlite3.connect(f\"{DATA}/proteins.db\")\n",
    "\n",
    "\n",
    "def load_raw_data():\n",
    "    intact_dups = []\n",
    "    intact_processed = []\n",
    "    with open(intact_f, \"r\") as i_f:\n",
    "        intact = csv.reader(i_f, delimiter=\",\")\n",
    "        original_count = 0\n",
    "        headings = next(intact)\n",
    "        progress = 0\n",
    "        for line in intact:\n",
    "            progress += 1\n",
    "            line_with_meta = dict(zip(headings[0].split(\"\\t\"), line[0].split(\"\\t\")))\n",
    "            original_count += 1\n",
    "            a = line_with_meta[\"#ID(s) interactor A\"]\n",
    "            a = a.replace('\"', \"\")\n",
    "            a = a.replace(\"uniprotkb:\", \"\")\n",
    "            a = a.replace(\"chebi:CHEBI:\", \"\")\n",
    "            a = a.replace(\"intact:EBI-\", \"\")\n",
    "            a = a.replace(\"ensembl:ENSG00000\", \"\")\n",
    "            b = line_with_meta[\"ID(s) interactor B\"]\n",
    "            b = b.replace('\"', \"\")\n",
    "            b = b.replace(\"uniprotkb:\", \"\")\n",
    "            b = b.replace(\"ensembl:ENSG00000\", \"\")\n",
    "            b = b.replace(\"intact:EBI-\", \"\")\n",
    "            key = tuple(sorted((a, b)))\n",
    "            line_with_meta[\"akey\"] = key[0]\n",
    "            line_with_meta[\"bkey\"] = key[1]\n",
    "            if key not in intact_dups:\n",
    "                intact_dups.append(key)\n",
    "                line_with_meta[\"dup\"] = False\n",
    "            else:\n",
    "                line_with_meta[\"dup\"] = True\n",
    "            line_with_meta[\"id\"] = progress\n",
    "            intact_processed.append(line_with_meta)\n",
    "            if progress > LIMIT:\n",
    "                break\n",
    "\n",
    "            # pprint.pprint(intact_processed[line_with_meta[\"key\"]])\n",
    "    biogrid_dups = []\n",
    "    biogrid_matches = {}\n",
    "    match_number = 0\n",
    "    progress = 0\n",
    "    biogrid_processed = []\n",
    "    with open(biogrid_f, \"r\") as b_f:\n",
    "        biogrid = csv.DictReader(b_f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "        for line in biogrid:\n",
    "            progress += 1\n",
    "            sa = line[\"SWISS-PROT Accessions Interactor A\"].replace(\"-\", \"\").strip()\n",
    "            ta = line[\"TREMBL Accessions Interactor A\"].replace(\"-\", \"\").strip()\n",
    "            sb = line[\"SWISS-PROT Accessions Interactor B\"].replace(\"-\", \"\").strip()\n",
    "            tb = line[\"TREMBL Accessions Interactor B\"].replace(\"-\", \"\").strip()\n",
    "            # print(sa, sb, ta, tb)\n",
    "            key = (sa, sb)\n",
    "            line[\"akey\"] = sa\n",
    "            line[\"bkey\"] = sb\n",
    "            if key not in biogrid_dups:\n",
    "                biogrid_dups.append(key)\n",
    "                line[\"dup\"] = False\n",
    "            else:\n",
    "                line[\"dup\"] = True\n",
    "                line[\"id\"] = progress\n",
    "            biogrid_processed.append(line)\n",
    "            key = (ta, tb)\n",
    "            line[\"akey\"] = ta\n",
    "            line[\"bkey\"] = tb\n",
    "            if key not in biogrid_dups:\n",
    "                biogrid_dups.append(key)\n",
    "                line[\"dup\"] = False\n",
    "            else:\n",
    "                line[\"dup\"] = True\n",
    "                line[\"id\"] = progress\n",
    "            biogrid_processed.append(line)\n",
    "\n",
    "            \"\"\"for a in line[\"key\"][0]:\n",
    "                for a_i in a:\n",
    "                    for b in line[\"key\"][1]:\n",
    "                        for b_i in b:\n",
    "                            # print(a_i.strip(), b_i.strip())\n",
    "                            key = tuple(sorted((a_i, b_i)))\n",
    "                            line[\"akey\"] = key[0]\n",
    "                            line[\"bkey\"] = key[1]\n",
    "                            if key not in biogrid_dups:\n",
    "                                biogrid_dups.append(key)\n",
    "                                line[\"dup\"] = False\n",
    "                            else:\n",
    "                                line[\"dup\"] = True\n",
    "                            line[\"id\"] = progress\n",
    "                            biogrid_processed.append(line)\"\"\"\n",
    "\n",
    "            if progress > LIMIT:\n",
    "                break\n",
    "        intact = pd.DataFrame(intact_processed)\n",
    "        biogrid = pd.DataFrame(biogrid_processed)\n",
    "        print(intact.head())\n",
    "        print(biogrid.head())\n",
    "        return intact_processed, biogrid_processed\n",
    "\n",
    "\n",
    "def match():\n",
    "    \"\"\"not needed like this??\"\"\"\n",
    "    if (a_i, b_i) in intact_processed.keys():\n",
    "        print(f\"MATCH {match_number}\")\n",
    "        match_number += 1\n",
    "        line[\"match\"] = match_number\n",
    "        # intact_processed[\"key\"][\"match\"] = match_number\n",
    "        # print(f\"{intact_processed['key']['match']}\")\n",
    "        # print(f\"{intact_processed['key']['match']}\")\n",
    "        # continue\n",
    "    biogrid_matches[line[\"key\"]] = line\n",
    "    # pprint.pprint(biogrid_matches[line[\"key\"]])\n",
    "    biogrid_matches[line[\"id\"]] = line\n",
    "\n",
    "\n",
    "def write_pickles():\n",
    "    with open(\"intact_matches.pkl\", \"wb\") as im:\n",
    "        pickle.dump(intact_processed, im)\n",
    "\n",
    "    with open(\"biogrid_matches.pkl\", \"wb\") as bm:\n",
    "        pickle.dump(biogrid_matches, bm)\n",
    "    print(\"=\" * 80)\n",
    "    count = 0\n",
    "    for item in intact_processed.items():\n",
    "        count += 1\n",
    "        pprint.pprint(item)\n",
    "        print(\"-\" * 80)\n",
    "        \"\"\"if count > 20:\n",
    "            break\"\"\"\n",
    "    print(f\"Intact matches {count}\")\n",
    "    count = 0\n",
    "    for item in biogrid_matches.items():\n",
    "        count += 1\n",
    "        pprint.pprint(item)\n",
    "        print(\"-\" * 80)\n",
    "        \"\"\"if count > 20:\n",
    "            break\"\"\"\n",
    "    print(f\"Biogrid matches {count}\")\n",
    "\n",
    "\n",
    "\"\"\"add control total for all catgories\"\"\"\n",
    "\n",
    "\n",
    "def read_files():\n",
    "    with open(\"biogrid_matches.pkl\", \"rb\") as bm:\n",
    "        biogrid_matches = pickle.load(bm)\n",
    "    with open(\"intact_matches.pkl\", \"rb\") as im:\n",
    "        intact_matches = pickle.load(im)\n",
    "    return intact_matches, biogrid_matches\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_menu():\n",
    "    print(\n",
    "        \"\"\"\n",
    "          1. Load raw files\n",
    "          2. Match protein data\n",
    "          3. List match data\n",
    "          4. Save match data\n",
    "          5. Load match data\n",
    "          9. Quit\n",
    "          option = input()\n",
    "          \"\"\"\n",
    "    )\n",
    "    option = input()\n",
    "    return option\n",
    "\n",
    "\n",
    "def main():\n",
    "    option = display_menu()\n",
    "    if option == \"1\":\n",
    "        intact, biogrid = load_raw_data()\n",
    "    exit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lessons",
   "language": "python",
   "name": "lessons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
